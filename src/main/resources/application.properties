spring.cloud.stream.propagateOriginalContentType=false

# ----   COSMOS TO DB2 SECTION----------------

#-- Topic to listen
spring.cloud.stream.bindings.cosmostodb2_success.destination=allow_bill_claim_write_success_db2
spring.cloud.stream.bindings.cosmostodb2_success.binder=kafka-qa1
spring.cloud.stream.bindings.cosmostodb2_success.group=wh_db2sync_receive_success
spring.cloud.stream.kafka.bindings.cosmostodb2_success.consumer.configuration.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.cloud.stream.kafka.bindings.cosmostodb2_success.consumer.configuration.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.cloud.stream.kafka.bindings.cosmostodb2_success.consumer.resetOffsets=true

#spring.cloud.stream.bindings.cosmostodb2_failure.destination=wh_db2sync_receive_failure
#spring.cloud.stream.bindings.cosmostodb2_failure.group=wh_db2sync_receive_failure
#spring.cloud.stream.kafka.bindings.cosmostodb2_failure.consumer.resetOffsets=true


# --------DB2TOCOSMOS STORE SECTION-----------


#-- Topic to listen
spring.cloud.stream.bindings.db2_cosmos_store_success.destination=default_ksql_processing_log
spring.cloud.stream.bindings.db2_cosmos_store_success.binder=kafka-qa2
spring.cloud.stream.bindings.db2_cosmos_store_success.group=db2_cosmos_store_success
spring.cloud.stream.kafka.bindings.db2_cosmos_store_success.consumer.configuration.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.cloud.stream.kafka.bindings.db2_cosmos_store_success.consumer.configuration.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.cloud.stream.kafka.bindings.db2_cosmos_store_success.consumer.resetOffsets=true






#---------- TO BE DEBUGGED BY MICROSOFT-----------------------

spring.cloud.stream.default-binder=kafka
spring.cloud.stream.kafka.binder.autoCreateTopics=false

#------- Binder 1-----------

spring.cloud.stream.binders.kafka-qa1.type=kafka
spring.cloud.stream.binders.kafka-qa1.environment.spring.cloud.stream.kafka.binder.brokers=ns-claims-us-q.servicebus.windows.net:9093
spring.cloud.stream.binders.kafka-qa1.environment.spring.cloud.stream.kafka.binder.configuration.security.protocol=SASL_SSL
spring.cloud.stream.binders.kafka-qa1.environment.spring.cloud.stream.kafka.binder.configuration.sasl.mechanism=PLAIN
spring.cloud.stream.binders.kafka-qa1.environment.spring.cloud.stream.kafka.binder.autoCreateTopics=false
spring.cloud.stream.binders.kafka-qa1.environment.spring.cloud.stream.kafka.binder.jaas.loginModule=org.apache.kafka.common.security.plain.PlainLoginModule
spring.cloud.stream.binders.kafka-qa1.environment.spring.cloud.stream.kafka.binder.jaas.options.username=$ConnectionString
spring.cloud.stream.binders.kafka-qa1.environment.spring.cloud.stream.kafka.binder.jaas.options.password=Endpoint=sb://Full password goes here please change


#------Binder 2---------

spring.cloud.stream.binders.kafka-qa2.type=kafka
spring.cloud.stream.binders.kafka-qa2.environment.spring.cloud.stream.kafka.binder.brokers=ns-po-db2-us-q.servicebus.windows.net:9093
spring.cloud.stream.binders.kafka-qa2.environment.spring.cloud.stream.kafka.binder.configuration.security.protocol=SASL_SSL
spring.cloud.stream.binders.kafka-qa2.environment.spring.cloud.stream.kafka.binder.configuration.sasl.mechanism=PLAIN
spring.cloud.stream.binders.kafka-qa2.environment.spring.cloud.stream.kafka.binder.autoCreateTopics=false
spring.cloud.stream.binders.kafka-qa2.environment.spring.cloud.stream.kafka.binder.jaas.loginModule=org.apache.kafka.common.security.plain.PlainLoginModule
spring.cloud.stream.binders.kafka-qa2.environment.spring.cloud.stream.kafka.binder.jaas.options.username=$ConnectionString
spring.cloud.stream.binders.kafka-qa2.environment.spring.cloud.stream.kafka.binder.jaas.options.password=Endpoint=sb://Full password goes here please change


#  ISSUES ABOVE
#
##Issue 1: if both binders point to two different eventhub in single cluster either one of them will be selected as group coordinator which is not correct which needs to be addressed.
##
#
#
#ISSUE 2:- if two eventhubs are not in cluster but dedicated ones then authorization issue
#
#OBSERVATION :- if two binder and configured to point localhost kafka instance they work as expected. The above given is a working example where one is eventhub and other is localhost

#so two different coordinators are selected.